1) Развернуть локально LLM модель с использованием python. Выбрать модель на Hugging Face, подходящую по ресурсам ПК. Сравнить несколько вариантов, по каким показателям происходил выбор.
2) Реализовать чтение текста из txt файла (текст на свой выбор).
Составить и протестировать 3-4 промпта для получения краткого содержания, анализа текста, переформулирования в другом стиле, извлечения какой-либо информации из текста. Ответы вывести в табличном формате, оценить их качество, подумать, какие решения могли бы его улучшить.
---------------
Дополнительное задание: создать простой веб-интерфейс для общения с моделью (gradio, streamlit и т.д)

По результатам выполнения составить отчет. Описать, какие инструменты и почему были выбраны, какие дополнения могли бы улучшить качество решения.



## Как запускать:

### Установка зависимостей:

``python -m venv venv``

``source venv/bin/activate``

``pip install -r requirements.txt``

### Запуск локально:


``uvicorn app:app --reload``


### Запуск в docker:


``cd docker``

``./docker-build.sh`` - создать docker image

``docker run -p 8000:8000 arina/sber:master``


### Или через docker compose:


``./docker-build.sh``

``./docker-compose-up.sh`` - запустить контейнер

